# Cấu hình thêm một compute node cho Cụm Openstack.

Ở bài này mình sẽ cấu hình thêm một Compute node cho cụm Openstack hiện tại của mình( Hiện cụm có một node controller và một node compute).


## Mô hình cài đặt

- Controler node:
  - IP: 
    - `eth0`: 192.168.30.171/24 - Management Network
    - `eth1`: 192.168.40.171/24 - Self-service Network
    - `eth2`.                   - Provider network.
- Compute node 1:(Đã cài đặt)
  - IP: 
    - `eth0`: 192.168.30.172/24 - Management Network
    - `eth1`: 192.168.40.172/24 - Self-service Network
    - `eth2`.                   - Provider network.
- Compute node 2:(Node mới sẽ cài đặt trong bài này)
  - IP: 
    - `eth0`: 192.168.30.176/24 - Management Network
    - `eth1`: 192.168.40.176/24 - Self-service Network
    - `eth2`.                   - Provider network.   


## Chuẩn bị môi trường
### Cấu hình mạng.
- Cấu hình địa chỉ IP của Compute node 2 theo mô hình trên.
- Cấu hình hostname cho server.
- Tắt SElinux
- Tắt NetworkManager
- Cấu hình phân giải hostname:
```
cat << EOF >> /etc/hosts
# controller
192.168.30.171       controller

# compute1
192.168.30.172       compute1

#compute2
192.168.30.176       compute2
EOF
```


### Cấu hình đồng bộ thời gian.
 Cấu hình chrony trên compute node 2 để đồng bộ thời gian từ controller.
- Cài gói:
```
yum install -y chrony
```
- Sửa file cấu hình `/etc/chrony.conf` thêm dòng sau để đồng bộ thời gian từ controller:
```
server controller iburst
```
- Comment hoặc xóa các dòng trỏ đến server khác.

- Khởi động dịch vụ:
```
systemctl restart chronyd.service
systemctl enable chronyd.service
```

- Kiểm tra lại với câu lệnh:
```
chronyc sources
```

### Cài đặt gói Openstack

- Cấu hình bật Openstack Repository:
```
yum install -y centos-release-openstack-train
```

- Hoàn tất cài đặt:
```
yum upgrade
```
```
yum install python-openstackclient
```

## Cài đặt và cấu hình
### Cài đặt và cấu hình Nova trên compute node 2.

#### Cài đặt và cấu hình các thành phần
1. Cài đặt gói cần thiết
```
yum install -y openstack-nova-compute
```
2. Backup và chỉnh sửa file cấu hình **/etc/nova/nova.conf**:
```
mv /etc/nova/nova.conf /etc/nova/nova.conf.orig
cat << 'EOF' >/etc/nova/nova.conf
[DEFAULT]
enabled_apis = osapi_compute,metadata
transport_url = rabbit://openstack:RABBIT_PASS@controller:5672
my_ip = 192.168.30.176
use_neutron = true
firewall_driver = nova.virt.firewall.NoopFirewallDriver

[api]
auth_strategy = keystone

[keystone_authtoken]
www_authenticate_uri = http://192.168.30.171:5000/
auth_url = http://192.168.30.171:5000/
memcached_servers = 192.168.30.171:11211
auth_type = password
project_domain_name = Default
user_domain_name = Default
project_name = service
username = nova
password = NOVA_PASS

[vnc]
enabled = true
server_listen = 0.0.0.0
server_proxyclient_address = $my_ip
novncproxy_base_url = http://192.168.30.171:6080/vnc_auto.html

[glance]
api_servers = http://192.168.30.171:9292

[oslo_concurrency]
lock_path = /var/lib/nova/tmp

[placement]
region_name = RegionOne
project_domain_name = Default
project_name = service
auth_type = password
user_domain_name = Default
auth_url = http://192.168.30.171:5000/v3
username = placement
password = PLACEMENT_PASS

EOF
```

#### Hoàn tất cài đặt
1. Kiểm tra phần cứng hỗ trợ
- Chạy lệnh sau để kiểm tra:
```
egrep -c '(vmx|svm)' /proc/cpuinfo
```
Nếu kết quả trả về 1 hoặc lớn hơn thì Compute node hỗ trợ phần cứng phù hợp để chạy và không cần phải cấu hình thêm.


2. Khởi động dịch vụ Compute:
```
systemctl enable libvirtd.service openstack-nova-compute.service
systemctl start libvirtd.service openstack-nova-compute.service
```

### Cài đặt và cấu hình Neutron trên Compute node 2 sử dụng openvswitch.
#### Chuẩn bị
- Cài đặt các gói thành phần:
```
yum install openstack-neutron-openvswitch ebtables ipset openvswitch -y
```
#### Cấu hình neutron
- Chỉnh sửa file cấu hình của neutron:
```
cp -p /etc/neutron/neutron.conf  /etc/neutron/neutron.conf.origin
cat << EOF > /etc/neutron/neutron.conf
[DEFAULT]
transport_url = rabbit://openstack:RABBIT_PASS@controller:5672/
auth_strategy = keystone

[keystone_authtoken]
www_authenticate_uri = http://controller:5000
auth_url = http://controller:5000
memcached_servers = controller:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = neutron
password = NEUTRON_PASS

[oslo_concurrency]
lock_path = /var/lib/neutron/tmp

EOF
```

- Bật openvswitch:
```
systemctl restart openvswitch
systemctl enable openvswitch
```
- Tạo bridge:
```
ovs-vsctl add-br br-provider
ovs-vsctl add-port br-provider eth2
```


- Cấu hình cho openvswitch-agent theo mô hình selfservice:
```
cp -p  /etc/neutron/plugins/ml2/openvswitch_agent.ini /etc/neutron/plugins/ml2/openvswitch_agent.ini.origin
cat << EOF > /etc/neutron/plugins/ml2/openvswitch_agent.ini
[ovs]
bridge_mappings = provider:br-provider
local_ip = 192.168.40.176

[agent]
tunnel_types = vxlan
l2_population = True

[securitygroup]
firewall_driver = iptables_hybrid
EOF

```

- Bật module bridge netfilter:
```
modprobe br_netfilter 
```

- Sửa nova-compute để thêm thông tin đăng nhập của neutron :
```
cat << EOF >> /etc/nova/nova.conf
[neutron]
auth_url = http://controller:5000
auth_type = password
project_domain_name = default
user_domain_name = default
region_name = RegionOne
project_name = service
username = neutron
password = NEUTRON_PASS
EOF
```

#### Hoàn tất cài đặt trên compute node

- Khởi động lại dịch vụ Nova Compute để nhận cấu hình:
```
systemctl restart openstack-nova-compute.service
```

- Khởi động và cấu hình tự khởi động cho LinuxBridge Agent của Neutron:
```
systemctl enable neutron-openvswitch-agent.service
systemctl start neutron-openvswitch-agent.service
```
- Cấu hình firewalld cho phép novnc trên controller có thể kết nối đến console của máy ảo:
```
firewall-cmd --add-port=5900-5999/tcp --permanent
firewall-cmd --reload
```
### Cấu hình thêm host mới vào cell
- Trên controller node:
```
nova-manage cell_v2 discover_hosts --verbose
```